
    <!DOCTYPE html>
    <html lang="en">
    <head>
    <meta charset="utf-8">
    <link rel="stylesheet" href="../assets/site.css">
    </head>
    <body style="
        background:#f6f7fb;
        padding:20px;
        color:#1f2937;
    ">
    <a id="top"></a>
    
      <div style="
          max-width:900px;
          margin:0 auto;
          background:#ffffff;
          border-radius:14px;
          padding:26px;
          box-shadow:0 6px 18px rgba(0,0,0,0.08);
          border:1px solid #eef0f4;
      ">

        <div style="display:flex;align-items:flex-end;justify-content:space-between;gap:14px;flex-wrap:wrap;">
          <div>
            <h1 style="margin:0;font-size:26px;line-height:1.2;color:#111827;">
              Bi-weekly Research Digest
            </h1>
            <p style="margin:8px 0 0;font-size:14px;color:#4b5563;">
              <b>Date range:</b> 2025-05-16 → 2025-05-31<br>
              <b>Total relevant papers:</b> 6
            </p>
          </div>
        </div>

        <h2 style="
            margin:26px 0 10px;
            font-size:18px;
            border-bottom:1px solid #e5e7eb;
            padding-bottom:8px;
            color:#111827;
        ">
          Summary by Journal
        </h2>

        <ul style="margin:10px 0 0;padding-left:18px;color:#374151;line-height:1.7;">
    <li><a href='#journal-management-science' style='text-decoration:none;color:#2563eb;'><b>Management Science</b></a>: 4</li><li><a href='#journal-psychological-review' style='text-decoration:none;color:#2563eb;'><b>Psychological Review</b></a>: 1</li><li><a href='#journal-nature-human-behaviour' style='text-decoration:none;color:#2563eb;'><b>Nature Human Behaviour</b></a>: 1</li></ul>
        <a id="journal-management-science"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        Management Science
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Discrete Choice via Sequential Search 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>It studies how information search before a choice shapes discrete decisions and product assortment/pricing. It derives closed-form predictions and shows that ignoring search dynamics can distort expected outcomes.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Kosilova, N., Alptekinoğlu, A.</div>
                <div><b>Published:</b> 2025-05</div>
                <div><b>Relevance Score:</b> 0.53</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2023.01552' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2023.01552</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Essentially every choice involves an information collection or search phase prior to a decision-making phase that culminates in a choice. To study the information collection phase within an important class of search problems and understand how it influences the final choice, we embed an analytically tractable discrete choice model in a classical model of sequential search with perfect recall. Although significant progress has been made in the theory literature in analyzing consumers’ discrete choice behavior using random utility models, discrete choice through a sequential search process has not received enough attention at least in part because of analytical intractability issues. We build on the seminal Pandora’s Problem as a model of sequential search with perfect recall and on Exponomial Choice as a model of discrete choice (with each choice specified by a deterministic or observable utility component minus a random or unobservable utility component following an exponential distribution). We derive the search path and final choice probabilities in closed form, develop all the analytical tools to optimize prices for a given assortment of products, and show that the optimal assortment must contain some number of highest-value products at optimal prices. These results enable joint optimization of assortment and prices efficiently. The structure of the solution features a distinct group of products that are priced just so they remain on the search path with higher probability. Through simulation studies, allowing us to control the ground truth, we also show that our model is competitive against the state of the art in empirical modeling of sequential search and that ignoring sequential search distorts both optimal variety and pricing decisions in an upward direction. This paper was accepted by Omar Besbes, revenue management and market analytics. Supplemental Material: The online appendix is available at https://doi.org/10.1287/mnsc.2023.01552 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Uncertain Search with Knowledge Transfer 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>It studies how a single decision maker samples among similar options when values have observable (population) and unobservable (idiosyncratic) parts, learns at both levels, and uses threshold-based rules to decide whether to continue, accept, or switch, highlighting how multi-level uncertainty shapes decision processes.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Huh, W., Kim, M., Lin, M.</div>
                <div><b>Published:</b> 2025-05</div>
                <div><b>Relevance Score:</b> 0.52</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2023.00309' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2023.00309</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">We consider a sequential search over a group of similar alternatives. The individual value of an alternative contains two components: an observable utility and an idiosyncratic value. Observable utilities share an unknown population distribution, which captures the similarity across the alternatives and allows for knowledge transfer within the group. Once a decision maker encounters an alternative, its utility is revealed immediately, whereas the idiosyncratic value is unobservable and needs to be learned by sampling. The goal is to select an alternative with the highest individual value, accounting for the sampling and search costs. A novel feature of this problem is the combination of the individual and population levels of learning. We formulate the problem as a Bayesian dynamic program and characterize the optimal policy by a threshold structure. We show that it depends on the difference between the mean estimates of the current alternative and the population. It is optimal to continue sampling if the difference is between a threshold pair; otherwise, accept the current alternative if it exceeds the upper threshold, and switch to a new one if it is below the lower threshold. Other structural properties are also derived to shed light on the effects of the two levels of learning. A key insight is that more uncertainty is preferable at the individual level, but less uncertainty is preferable at the population level. Various practical variants of the problem are also considered. This paper was accepted by Ilia Tsetlin, behavioral economics and decision analysis. Funding: W. T. Huh acknowledges support from the NSERC Discovery Grants (RGPIN 2020-04213) and the Canada Research Chair Program. The work of M. J. Kim was supported by the Natural Sciences and Engineering Research Council of Canada [NSERC Discovery Grant RGPIN-2024-05213]. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2023.00309 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Humans’ Use of AI Assistance: The Effect of Loss Aversion on Willingness to Delegate Decisions 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>Across multiple experiments, loss framing reduces algorithm aversion and equalizes the tendency to delegate to AI and human assistants, with framing increasing situational awareness across tasks of varying complexity.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Bockstedt, J., Buckman, J.</div>
                <div><b>Published:</b> 2025-05</div>
                <div><b>Relevance Score:</b> 0.46</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2024.05585' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2024.05585</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">As artificial intelligence (AI) tools have become pervasive in business applications, so too have interactions between AI and humans in business processes and decision-making. A growing area of research has focused on human decision and task delegation to AI assistants. Simultaneously, extensive research on algorithm aversion—humans’ resistance to algorithm-based decision tools—has demonstrated potential barriers and issues with AI applications in business. In this paper, we test a simple strategy for mitigating algorithm aversion in the context of AI task delegation. We show that simply changing the framing of decision tasks can allay algorithm aversion. Through multiple studies, we found that participants exhibited a strong preference for human assistance over AI assistance when they were rewarded for task performance (i.e., money was gained for good performance), even when the AI had been shown to outperform the human assistant on the task. Alternatively, when we reframed the task such that the participant experienced losses for poor performance (i.e., money was taken from their endowment for poor performance), the bias for preferring human assistance was removed. Under loss framing, participants delegated the decision task to human and AI assistants at similar rates. We demonstrate this finding across tasks at differing levels of complexity and at different incentive sizes. We also provide evidence that loss framing increases situational awareness, which drives the observed effects. Our results offer useful insights on reducing algorithm aversion that extend the literature and provide actionable suggestions for practitioners and managers. This paper has been This paper was accepted by Dongjun Wu for the Special Issue on the Human-Algorithm Connection. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2024.05585 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Incentives, Framing, and Reliance on Algorithmic Advice: An Experimental Study 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>An experimental study showing that compensation structures and AI-framing modulate how much decision makers rely on algorithmic advice and how they perform on price estimates, with attention to process-level engagement and human–AI interaction.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Greiner, B., Grünwald, P., Lindner, T., Lintner, G., Wiernsperger, M.</div>
                <div><b>Published:</b> 2025-05</div>
                <div><b>Relevance Score:</b> 0.44</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2022.02777' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2022.02777</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Managerial decision makers are increasingly supported by advanced data analytics and other artificial intelligence (AI)-based technologies, but they are often found to be hesitant to follow the algorithmic advice. We examine how compensation contract design and framing of an AI algorithm influence decision makers’ reliance on algorithmic advice and performance in a price estimation task. Based on a large sample of almost 1,500 participants, we find that compared with a fixed compensation, both compensation contracts based on individual performance and tournament contracts lead to an increase in effort duration and to more reliance on algorithmic advice. We further find that using an AI algorithm that is framed as also incorporating human expertise has positive effects on advice utilization, especially for decision makers with fixed pay contracts. By showing how widely used control practices, such as incentives and task framing, influence the interaction of human decision makers with AI algorithms, our findings have direct implications for managerial practice. This paper has been accepted by David Simchi-Levi for the Special Issue on the Human-Algorithm Connection. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.02777 .</span>
                </div>
              </div>
            </div>
            
        <a id="journal-psychological-review"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        Psychological Review
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Adapting to loss: A computational model of grief. 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The paper presents a computational model in which grief is framed as a reinforcement-learning process with memory replay, suggesting grief may help unlearn old habits and discover alternative rewards, supported by simulations of grief trajectories.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Dulberg, Z., Dubey, R., Cohen, J.</div>
                <div><b>Published:</b> 2025-05</div>
                <div><b>Relevance Score:</b> 0.42</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1037/rev0000567' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1037/rev0000567</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Grief is a reaction to loss that is observed across human cultures and even in other species. While the particular expressions of grief vary significantly, universal aspects include experiences of emotional pain and frequent remembering of what was lost. Despite its prevalence, and its obvious nature, considering grief from a functional perspective is puzzling: Why do we grieve? Why is it painful ? And why is it sometimes prolonged enough to be clinically impairing? Using the framework of reinforcement learning with memory replay, we offer answers to these questions and suggest, counterintuitively, that grief may function to maximize future reward. That is, grieving may help to unlearn old habits so that alternative sources of reward can be found. We additionally perform a set of simulations that identify and explore optimal grieving parameters and use our model to account for empirical phenomena such as individual differences in human grief trajectories. (PsycInfo Database Record (c) 2025 APA, all rights reserved).</span>
                </div>
              </div>
            </div>
            
        <a id="journal-nature-human-behaviour"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        Nature Human Behaviour
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Why people follow rules 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The study introduces CRISP and shows that a substantial portion of individuals conform to a costly rule due to intrinsic respect and social expectations, with modest contagion and modulation by incentives, highlighting psychological mechanisms behind rule-conformity at the individual level.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Gächter, S., Molleman, L., Nosenzo, D.</div>
                <div><b>Published:</b> 2025-05</div>
                <div><b>Relevance Score:</b> 0.37</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1038/s41562-025-02196-4' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1038/s41562-025-02196-4</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Abstract Why people follow rules, especially laws and social norms, is debated across the human sciences. The importance of intrinsic respect for rules is particularly controversial. To reveal the behavioural principles of rule-following, we develop CRISP, an interdisciplinary framework that explains rule-conformity C as a function of intrinsic respect for rules R , extrinsic incentives I , social expectations S and social preferences P . We deploy CRISP in four series of online experiments with 14,034 English-speaking participants. In our baseline experiments, 55–70% of participants conform to an arbitrary costly rule, even though they act anonymously and alone, and violations hurt no one. We show that people expect rule-conformity and view it as socially appropriate. Rule-breaking is contagious but remains moderate. Pro-social motives and extrinsic incentives increase rule-conformity, but unconditional rule-following and social expectations explain most of it. Our results demonstrate that respect for rules and social expectations are basic elements of rule-conformity that can explain why people follow laws and social norms even without extrinsic incentives and social preferences.</span>
                </div>
              </div>
            </div>
            
      </div>
      <a href="#top" class="back-to-top" aria-label="Back to top">
        ↑
        </a>

    </body>
    </html>
    