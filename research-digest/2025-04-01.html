
    <!DOCTYPE html>
    <html lang="en">
    <head>
    <meta charset="utf-8">
    <link rel="stylesheet" href="../assets/site.css">
    </head>
    <body style="
        background:#f6f7fb;
        padding:20px;
        color:#1f2937;
    ">
    <a id="top"></a>
    
      <div style="
          max-width:900px;
          margin:0 auto;
          background:#ffffff;
          border-radius:14px;
          padding:26px;
          box-shadow:0 6px 18px rgba(0,0,0,0.08);
          border:1px solid #eef0f4;
      ">

        <div style="display:flex;align-items:flex-end;justify-content:space-between;gap:14px;flex-wrap:wrap;">
          <div>
            <h1 style="margin:0;font-size:26px;line-height:1.2;color:#111827;">
              Bi-weekly Research Digest
            </h1>
            <p style="margin:8px 0 0;font-size:14px;color:#4b5563;">
              <b>Date range:</b> 2025-03-16 → 2025-03-31<br>
              <b>Total relevant papers:</b> 3
            </p>
          </div>
        </div>

        <h2 style="
            margin:26px 0 10px;
            font-size:18px;
            border-bottom:1px solid #e5e7eb;
            padding-bottom:8px;
            color:#111827;
        ">
          Summary by Journal
        </h2>

        <ul style="margin:10px 0 0;padding-left:18px;color:#374151;line-height:1.7;">
    <li><a href='#journal-journal-of-experimental-psychology-learning-memory-and-cognition' style='text-decoration:none;color:#2563eb;'><b>Journal of Experimental Psychology: Learning, Memory, and Cognition</b></a>: 1</li><li><a href='#journal-psychological-review' style='text-decoration:none;color:#2563eb;'><b>Psychological Review</b></a>: 1</li><li><a href='#journal-management-science' style='text-decoration:none;color:#2563eb;'><b>Management Science</b></a>: 1</li></ul>
        <a id="journal-journal-of-experimental-psychology-learning-memory-and-cognition"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        Journal of Experimental Psychology: Learning, Memory, and Cognition
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Frequency effects in human category learning. 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The paper shows that category frequency biases categorization and that decisions are better captured by a recency-weighted exemplar model with accumulative evidence, rather than prototype averaging, across multiple experiments with novel transfer items.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Yang, D., Worthy, D.</div>
                <div><b>Published:</b> 2025-03</div>
                <div><b>Relevance Score:</b> 0.41</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1037/xlm0001474' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1037/xlm0001474</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">This study investigated the assumptions of prototype and exemplar models of human category learning, with a particular focus on the impact of category frequency. We used baseline and recency-weighted variants of prototype and exemplar models to examine the computational mechanisms underlying categorization decisions when one category was presented more frequently than the other. We employed extensive sets of stimuli derived from bivariate normal distributions and manipulated category frequency during training across four experiments using different category structures. In the transfer phases, participants classified novel stimuli. Across all studies, the results revealed a significant frequency effect, with participants showing a preference for categorizing novel items as members of the more frequently encountered category. This preference extended to transfer stimuli outside the trained region of the stimulus space. Model-based analyses indicated that the recency-weighted generalized context model exemplar model, which computes summed similarity via a Decay reinforcement learning rule, consistently outperformed other models in fitting the data and accurately reproducing the observed classification patterns across all experiments. Both prototype models failed to account for the observed frequency effects. While the baseline generalized context model was able to account for frequency effects, it did not capture recency effects. These findings suggest that relative category frequency influences human behavior when categorizing novel items. The computational modeling results revealed that evidence for categorization decisions is recency-weighted and accumulative rather than averaged. (PsycInfo Database Record (c) 2025 APA, all rights reserved).</span>
                </div>
              </div>
            </div>
            
        <a id="journal-psychological-review"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        Psychological Review
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Beliefs about perception shape perceptual inference: An ideal observer model of detection. 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The paper tests how beliefs about perception influence detection decisions under noisy, occluded stimuli using an ideal observer model, highlighting process-level mechanisms and individual differences in perceptual inference.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Mazor, M., Moran, R., Press, C.</div>
                <div><b>Published:</b> 2025-03</div>
                <div><b>Relevance Score:</b> 0.4</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1037/rev0000552' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1037/rev0000552</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">According to Bayesian, &quot;inverse optics&quot; accounts of vision, perceiving is inferring the most likely state of the world given noisy sensory data. This inference depends not only on prior beliefs about the world but also on an internal model specifying how world states translate to visual sensations. Alternative accounts explain perceptual decisions as a rule-based process, with no role for such beliefs about perception. Here, we contrast the two alternatives, focusing on decisions about perceptual absence as a critical test case. We present data from three preregistered experiments where participants performed a near-threshold detection task under different levels of partial stimulus occlusion, thereby visibly manipulating the measurement function going from external world states to internal perceptual states. We find that decisions about presence and absence are differentially sensitive to sensory evidence and occlusion. Furthermore, we observe reliably opposite individual-level effects of occlusion on decisions about absence. Our model accounts for these findings by postulating robust individual differences in the incorporation of beliefs about visibility into perceptual inferences, independent of population variability in visibility itself. We discuss implications for the varied and inferential nature of visual perception more broadly. (PsycInfo Database Record (c) 2025 APA, all rights reserved).</span>
                </div>
              </div>
            </div>
            
        <a id="journal-management-science"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        Management Science
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Human-Algorithm Collaboration with Private Information: Naïve Advice-Weighting Behavior and Mitigation 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The paper shows a bias where people overweight or underweight algorithmic predictions relative to their private information in demand forecasting, demonstrates that feature transparency helps users discriminate how to deviate from algorithms, and reports interventions that shift behavior toward reliance on private information, reducing prediction error.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Balakrishnan, M., Ferreira, K., Tong, J.</div>
                <div><b>Published:</b> 2025-03</div>
                <div><b>Relevance Score:</b> 0.39</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2022.03850' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2022.03850</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Even if algorithms make better predictions than humans on average, humans may sometimes have private information that an algorithm does not have access to that can improve performance. How can we help humans effectively use and adjust recommendations made by algorithms in such situations? When deciding whether and how to override an algorithm’s recommendations, we hypothesize that people are biased toward following naïve advice-weighting (NAW) behavior; they take a weighted average between their own prediction and the algorithm’s prediction, with a constant weight across prediction instances regardless of whether they have valuable private information. This leads to humans overadhering to the algorithm’s predictions when their private information is valuable and underadhering when it is not. In an online experiment where participants were tasked with making demand predictions for 20 products while having access to an algorithm’s predictions, we confirm this bias toward NAW and find that it leads to a 20%–61% increase in prediction error. In a second experiment, we find that feature transparency—even when the underlying algorithm is a black box—helps users more effectively discriminate how to deviate from algorithms, resulting in a 25% reduction in prediction error. We make further improvements in a third experiment via an intervention designed to move users away from advice weighting and instead, use only their private information to inform deviations, leading to a 34% reduction in prediction error. This paper has been This paper was accepted by Elena Katok for the Special Issue on the Human-Algorithm Connection. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.03850 .</span>
                </div>
              </div>
            </div>
            
      </div>
      <a href="#top" class="back-to-top" aria-label="Back to top">
        ↑
        </a>

    </body>
    </html>
    