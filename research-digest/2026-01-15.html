
    <!DOCTYPE html>
    <html lang="en">
    <head>
    <meta charset="utf-8">
    <link rel="stylesheet" href="../assets/site.css">
    </head>
    <body style="
        background:#f6f7fb;
        padding:20px;
        color:#1f2937;
    ">
    <a id="top"></a>
    
      <div style="
          max-width:900px;
          margin:0 auto;
          background:#ffffff;
          border-radius:14px;
          padding:26px;
          box-shadow:0 6px 18px rgba(0,0,0,0.08);
          border:1px solid #eef0f4;
      ">

        <div style="display:flex;align-items:flex-end;justify-content:space-between;gap:14px;flex-wrap:wrap;">
          <div>
            <h1 style="margin:0;font-size:26px;line-height:1.2;color:#111827;">
              Bi-weekly Research Digest
            </h1>
            <p style="margin:8px 0 0;font-size:14px;color:#4b5563;">
              <b>Date range:</b> 2026-01-01 → 2026-01-15<br>
              <b>Total relevant papers:</b> 45
            </p>
          </div>
        </div>

        <h2 style="
            margin:26px 0 10px;
            font-size:18px;
            border-bottom:1px solid #e5e7eb;
            padding-bottom:8px;
            color:#111827;
        ">
          Summary by Journal
        </h2>

        <ul style="margin:10px 0 0;padding-left:18px;color:#374151;line-height:1.7;">
    <li><a href='#journal-american-economic-review' style='text-decoration:none;color:#2563eb;'><b>American Economic Review</b></a>: 2</li><li><a href='#journal-cognition' style='text-decoration:none;color:#2563eb;'><b>Cognition</b></a>: 9</li><li><a href='#journal-psychological-review' style='text-decoration:none;color:#2563eb;'><b>Psychological Review</b></a>: 3</li><li><a href='#journal-journal-of-economic-psychology' style='text-decoration:none;color:#2563eb;'><b>Journal of Economic Psychology</b></a>: 2</li><li><a href='#journal-management-science' style='text-decoration:none;color:#2563eb;'><b>Management Science</b></a>: 15</li><li><a href='#journal-cognitive-psychology' style='text-decoration:none;color:#2563eb;'><b>Cognitive Psychology</b></a>: 2</li><li><a href='#journal-journal-of-experimental-psychology-learning-memory-and-cognition' style='text-decoration:none;color:#2563eb;'><b>Journal of Experimental Psychology: Learning, Memory, and Cognition</b></a>: 2</li><li><a href='#journal-trends-in-cognitive-sciences' style='text-decoration:none;color:#2563eb;'><b>Trends in Cognitive Sciences</b></a>: 1</li><li><a href='#journal-psychological-science' style='text-decoration:none;color:#2563eb;'><b>Psychological Science</b></a>: 2</li><li><a href='#journal-journal-of-behavioral-decision-making' style='text-decoration:none;color:#2563eb;'><b>Journal of Behavioral Decision Making</b></a>: 3</li><li><a href='#journal-jep-general' style='text-decoration:none;color:#2563eb;'><b>JEP: General</b></a>: 3</li><li><a href='#journal-obhdp' style='text-decoration:none;color:#2563eb;'><b>OBHDP</b></a>: 1</li></ul>
        <a id="journal-american-economic-review"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        American Economic Review
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Risk Preferences and Field Behavior: The Relevance of Higher-Order Risk Preferences 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The study measures higher-order risk preferences in adolescents and shows these preferences predict fields like health and financial decisions, arguing that ignoring prudence/temperance can misstate risk-behavior relationships.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Schneider, S., Sutter, M.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.58</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1257/aer.20211217' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1257/aer.20211217</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Using new methods, we measure the intensities of higher-order risk preferences (prudence and temperance) in an incentivized experiment with 658 adolescents. Aligned with theory, we find that higher-order risk preferences are strongly related to field behavior, including prevention, health, addictive behavior, and financial decision-making. Most importantly, we show that ignoring prudence and temperance can yield misleading conclusions about the relation of risk preferences to field behavior, and that survey measures of risk tolerance often relate to field behavior because they capture higher-order risk preferences. (JEL C83, D81, D91, J13)</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Sequential Learning under Informational Ambiguity 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>Under informational ambiguity, sequential decisions lead to information cascades that are robust to many properties of the signals; even mild ambiguity can trigger herding when signals are bounded, and may induce incorrect herding when signals are unbounded.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Chen, J.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.45</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1257/aer.20231394' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1257/aer.20231394</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">This paper investigates a sequential social learning problem in which individuals face ambiguity about others’ signal structures and have max-min expected utility preferences, thereby exhibiting ambiguity aversion. Unlike previous findings, which suggest that learning outcomes depend on the specifics of the learning environment, this study establishes information cascades as a robust outcome under ambiguity. With sufficient ambiguity, cascades arise almost surely, regardless of the statistical properties of signal structures. Moreover, standard results predicting the absence of cascades can easily break down: Even minimal ambiguity can trigger cascades when signals are bounded and lead to incorrect herding when signals are unbounded. (JEL D81, D82, D83)</span>
                </div>
              </div>
            </div>
            
        <a id="journal-cognition"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        Cognition
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                The first attribute heuristic influences risky choice preferences 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The study introduces the First Attribute Heuristic, showing that the first available attribute (probability or money) can dominantly drive risky choices, implying context-driven, on-the-spot construction of risk preferences and highlighting process-level effects beyond standard theories.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Teal, J., Kusev, P., Martin, R.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.56</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1016/j.cognition.2025.106298' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1016/j.cognition.2025.106298</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">© 2025 The AuthorsBehavioral science research indicates that people appear to construct their risk preferences ‘on the fly’, informed by decision making context and task (Kusev et al., 2020). However, very little research has explored people&#39;s psychological processing during decision-making ‘on the fly’. Accordingly, in this article we propose, explore, and establish the First Attribute Heuristic (FAH) in the domain of risky decision-making. FAH is a simple decision-making heuristic which is based on binary comparisons of values on the first contextually available attribute (e.g., probability or money). In three studies we found that the participants&#39; preference and likelihood of selecting the option with the dominant value over the option with the inferior value increase, when these values are presented on the first contextually available attribute. Importantly, our experimental findings provide further evidence that participants&#39; risk preferences are constructed ‘on the fly’. Specifically, decision-makers use FAH (a simple decision-making heuristic), which contributes to the lability of their preferences. Importantly, this heuristic and its influence on human risky decision-making are not anticipated by well-established behavioral theories such as Expected Utility Theory, Prospect Theory, and the Priority Heuristic.</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Strategic reasoning under pressure: Testing heuristics in higher-order theory of mind 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>Under time pressure, participants use probabilistic heuristics to approximate others’ future states rather than engaging in full recursive ToM, revealing process-level cognitive strategies in social decision making.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Stanley, G.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.52</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1016/j.cognition.2025.106331' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1016/j.cognition.2025.106331</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">© 2025Higher-order Theory of Mind (ToM+)—the recursive ability to understand that others have thoughts about thoughts—is pivotal to complex social interactions but can be cognitively demanding. This study examines how individuals cope when ToM+ reasoning exceeds their cognitive limits, contrasting a model predicting “blindness” to future states with a model predicting averaging over future states. Conducted on a new online platform called the Morality Game and using a series of 32 time-pressured sequential-choice games, participants&#39; errors reveal consistent support for the probabilistic model, indicating that when precise higher-order reasoning is unfeasible, individuals do not simply ignore future possibilities. Instead, they approximate future states using probabilistic heuristics rather than explicit recursive reasoning. By clarifying how individuals rely on such heuristics when full deliberation is impractical, these findings provide a clearer framework for understanding the mental shortcuts that shape ToM+ under cognitive strain, thereby informing more precise methods for investigating and modeling complex social inference.</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Children leverage predictive representations for flexible, value-guided choice 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The authors test whether children and adults use predictive representations to guide flexible, value-based choices and whether offline replanning aids decision-making. They find early use of successor representations and limited impact of offline replanning, providing a mechanistic, process-level account of how structured knowledge guides decision-making.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Zhang, A., Nussenbaum, K., Hartley, C., Kahn, A., Daw, N., Nussenbaum, K., Daw, N.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.51</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1016/j.cognition.2025.106340' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1016/j.cognition.2025.106340</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">© 2025 The AuthorsBy harnessing a mental model of how the world works, learners can make flexible choices in changing environments. However, while children and adolescents readily acquire structured knowledge of their environments, relative to adults, they often demonstrate weaker signatures of leveraging this knowledge to plan actions. One explanation for these developmental differences is that using a mental model to prospectively simulate potential choices and their outcomes is computationally costly, taxing cognitive mechanisms that develop into adulthood. Here, we ask whether children effectively leverage structured knowledge to make flexible choices by relying on two alternative strategies that do not require costly mental simulation at choice time. First, through offline replanning, models can be queried before the time of choice to update the values of potential actions. Second, an abstracted predictive model, known as a successor representation (SR), can enable simplified computation of long-run reward values of candidate actions without requiring iterative simulation of multiple time steps. Here, across three experiments, we assessed whether children, adolescents, and adults aged 7–23 years similarly harness these learning strategies. In a reward revaluation task, we found that children flexibly updated their behavior by leveraging structured knowledge, but that across age, the opportunity for offline replanning during rest did not influence behavior. While participants may have leveraged a detailed mental model of the task structure, they may have also relied on simplified, predictive representations to guide their choices. We then directly tested whether children use predictive representations and observed early-emerging use of the SR, providing a mechanistic account of how children use structured knowledge to guide choice without detailed model-based simulation.</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Probability errors in adults&#39; and children&#39;s decision-making 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>A developmental study showing adults’ and children’s probability judgments exhibit conjunction fallacies influenced by outcome likelihood and related to social judgments; thinking aloud reduces social but not objective probability fallacies, highlighting cognitive representations and learning in probabilistic reasoning at the individual level.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Marshall, D., Meins, E.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.5</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1016/j.cognition.2025.106297' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1016/j.cognition.2025.106297</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">© 2025 The AuthorsThree studies evaluated Tversky and Kahneman&#39;s (1983) proposal that the conjunction fallacy (judging the probability of a conjunction of two events to be higher than that of its component events) arises due to the representativeness heuristic. Since such heuristic thinking is not innate and depends upon the individual learning the extent to which situations are likely to occur, our evaluation adopted a developmental approach. Study 1 (N = 82 adults; N = 71 4- to 5-year-olds), Study 2 (N = 130 adults; N = 148 4- to 11-year-olds), and Study 3 (N = 76 adults) assessed objective probability judgements by asking participants to determine whether a single player or a two-player team would win based on assigned poker chip (adults) or building block (children) distributions. Social judgements were based on descriptions of individuals. All three studies showed that adults&#39; conjunction fallacies in objective probability judgements were (a) influenced by the likelihood of winning, and (b) positively correlated with conjunction fallacies in judging social characteristics. Children&#39;s conjunction fallacies in objective probability judgements were not influenced by manipulating the probabilities assigned to either team, and did not differ as a function of children&#39;s age. Fallacies on the objective and social judgement tasks were positively correlated in 10- and 11-year-olds, but not in younger children. Study 3 showed a “thinking aloud” procedure (to facilitate rational, non-heuristic decision-making) reduced adults&#39; fallacies on the social judgement, but not the objective probability task. Findings are discussed in relation to developmental changes in decision-making, and common versus distinct cognitive processes associated with objective and social judgement errors.</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Learning to be confident: How agents learn confidence based on prediction errors 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The study shows that confidence judgments are dynamically learned from prediction errors via a simple learning rule, with a neural-network–like model predicting confidence better than a valence-based account, while objective performance remains unchanged by feedback.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Le Denmat, P., Desender, K., Verguts, T., Le Denmat, P.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.46</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1016/j.cognition.2025.106332' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1016/j.cognition.2025.106332</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">© 2025 Elsevier B.V.Decision confidence should normatively reflect the posterior probability of making a correct choice, conditional on relevant information. However, how individuals learn to calibrate their sense of confidence to that probability remains unknown. The standard approach to estimate any quantity is to use trial-by trial samples of that quantity to train a function approximator (such as a neural network) based on the prediction errors (quantity minus prediction of the quantity). We tested whether humans learn about confidence using this principle in a perceptual decision-making experiment where participants repeatedly alternated between two manipulated feedback regimes (negative vs positive) every few blocks of trials. As anticipated, confidence ratings tracked feedback, with confidence gradually increasing when participants received overall positive feedback (and thus positive prediction errors), and decreasing when receiving negative feedback (and thus negative prediction errors). These feedback-induced dynamic changes were specific to confidence, as objective performance was unaffected by the manipulation. We propose a single-layer neural network model for confidence which updates the computation of confidence based on trial-level prediction errors, and demonstrate that it better fits the behavioral data compared to a purely valence-based model. Taken together, these results show that the computation of confidence is dynamic: humans constantly update how they compute confidence based on prediction errors (feedback minus prediction), in a statistically efficient manner.</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                The development of probabilistic reasoning during early childhood 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The study investigates development of probabilistic reasoning in 3–5 year-olds via urn tasks, finding that older children more often choose the higher-proportion urn while younger children rely on heuristics, highlighting cognitive representations and process-level strategies in early risk-related judgments.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Placì, S., Pighin, S., Mastropasqua, T., Tentori, K., Placì, S.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.42</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1016/j.cognition.2025.106283' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1016/j.cognition.2025.106283</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">© 2025Previous results have been inconsistent regarding the age at which children can compute probabilities based on proportions, with estimates ranging from one to 12 years. The aim of our study was twofold: (I) to address previous inconsistencies and (II) to quantify reasoning skills in 3- to 5-year-old children using an experimental procedure that is simple and engaging but also allows for the control of possible competing heuristic strategies, which may lead to outcomes mimicking the correct answer. Specifically, children had to choose between two urns containing varying proportions of blue and yellow balls. They knew they would receive a reward if, after several random mixtures, a target (e.g., a blue) ball fell out of the chosen urn. If children understood probabilities, they should select the urn with a higher proportion of target balls. Alternative reasoning strategies were disentangled by manipulating the absolute and relative numbers of target versus non-target balls in the two urns across 18 trials. We found that most 5-year-olds and a smaller but non-negligible number of younger children consistently chose the urn with a higher proportion of target items. However, a significant portion of 3- and 4-year-olds’ responses appeared to be guided by heuristic strategies, with the most prevalent being choosing the urn with a higher number of target balls. These results provide a more comprehensive understanding of the development of probabilistic reasoning in young children and underscore the importance of using experimental procedures and stimuli that enhance reasoning abilities while controlling for competing strategies.</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Reversed effects of prior choices in cross-modal temporal decisions 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The paper shows that judgments of tempo changes in rhythms are attracted toward previous choices within the same modality but repelled across modalities, suggesting modality consistency modulates serial dependence in perceptual decision processes.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Li, B., Wang, B., Zaidel, A.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.4</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1016/j.cognition.2025.106294' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1016/j.cognition.2025.106294</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">© 2025 Elsevier B.V.Perception of a current stimulus is influenced by one&#39;s immediately preceding sensory experience. This phenomenon, termed “serial dependence”, affects perception of isochronous rhythm. However, it is unknown whether serial dependence affects perception of more complex temporal dynamics, such as changing tempo. Here, we tested the influence of serial dependence on perception of changes in tempo of a three-beat (two-interval) rhythm. In Experiment 1, participants were asked to classify whether visual or auditory stimulus rhythms (tested in separate blocks) had “accelerating” or “decelerating” tempo. In Experiment 2, the visual and auditory rhythms were interleaved to investigate serial dependencies across modalities. Current decisions were attracted toward previous choices, but only in the uni-modal conditions (when the previous and current trials were from the same modality, seen in both Experiments 1 and 2, for both vision and audition). Surprisingly, in the cross-modal conditions (of Experiment 2), the opposite – a repulsive effect of previous choices – was observed. Besides the effects of previous choices, previous stimuli (tempo changes in the previous trial) also influenced current decisions – exerting a repulsive effect in the uni-modal conditions (for both modalities in Experiment 2, and auditory, but not visual, in Experiment 1) – which was notably absent in the cross-modal conditions. Repulsive effects of previous choices from a different modality, in contrast to attractive choice effects within the same modality, suggests that changing modalities triggers choice switching. These results, along with the lack of influence of previous stimuli cross-modally, suggest that modality consistency is an important factor for serial dependence in the perception of rhythm.</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Spontaneous coordination with self-commitment: How the presence of others alters the strength, goal and timing of commitment 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>In various social conditions, people adjust how strongly and when they commit to goals in an individual task, with parallel-play triggering ToM inferences that bias goal selection and delay revealing intentions, indicating spontaneous bargaining and social-cognitive processing in commitment formation.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Cheng, S., Zhu, J., Zhou, J., Shen, M., Cheng, S., Gao, T., Gao, T., Gao, T., Cheng, S.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.38</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1016/j.cognition.2025.106287' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1016/j.cognition.2025.106287</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">© 2025 The AuthorsCommitment is a paradoxical feature of human behavior, often seen as both an irrational bias and a virtue for achieving goals. This study investigates its social roots, revealing how social contexts shape the strength, content, and timing of self-commitment, even in individual tasks. Through a series of game-like experiments, participants pursued one of two equally desirable goals via sequential actions under varied social conditions: alone in a private room (Experiment 1), alongside an optimal reinforcement learning (RL) agent (Experiment 2) or another human (Experiment 3) on a shared display, or alone with a mere passive observer present (Experiment 4). Our results demonstrate that (1) all social contexts consistently heightened self-commitment, underscoring its sensitivity to the public nature of tasks; (2) in parallel-play settings (Experiments 2 and 3), participants spontaneously inferred others&#39; intentions and avoided selecting the same goal, despite instructions that such avoidance was unnecessary, suggesting that theory-of-mind (ToM) inference of another agent is spontaneously evoked to bias goal selection; and (3) Bayesian ToM modeling indicated that participants delayed revealing their intentions in parallel-play settings but not in the mere-presence condition, implying that spontaneous bargaining with a potential partner, rather than mere social presence, prompts more cautious commitment formation. These findings illuminate that, even in individual tasks, self-commitment is deeply intertwined with social context, influencing how people manage their goals and interactions with others.</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                A criterion-placement theory of face matching 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>A criterion-placement theory explains how individual differences in decision thresholds drive face-matching decisions; when biases are accounted for, linkages between match and mismatch identifications become reliable, supporting a threshold-based cognitive model of identity judgments.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Baker, K., Bindemann, M., Mondloch, C., Hancock, P.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.36</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1016/j.cognition.2025.106319' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1016/j.cognition.2025.106319</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">© 2025 The AuthorsFace matching is an important applied task that requires binary decisions to pairs of face images to determine whether these depict the same person (an identity match) or different people (a mismatch). While these choices are mutually exclusive, performance for match and mismatch trials appears to be dissociable, which poses a problem for theory development. The current study demonstrates that this dissociation arises from systematic response biases, which reflect individual differences in the placement of decision-making thresholds to distinguish matches from mismatches. When these biases are controlled or partialled out from classification accuracy, reliable associations between match and mismatch identifications are found. This is demonstrated over two experiments with a sample of over 500 participants, several face-matching tests, and a series of data simulations. These findings support a cognitive theory in which individual differences in the placement of decision-making thresholds provide the mechanism by which the identification of face matches and mismatches are linked.</span>
                </div>
              </div>
            </div>
            
        <a id="journal-psychological-review"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        Psychological Review
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                A diffusion-based framework for modeling systematic, time-varying cognitive processes. 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The paper presents a diffusion model with time-varying parameters to track how drift rate and caution evolve over time, arguing that neglecting such dynamics biases standard parameter estimates; it offers a framework for robustly modeling time-varying cognitive processes in decision tasks.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Alister, M., Evans, N.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.54</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1037/rev0000609' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1037/rev0000609</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">As people engage in tasks over extended periods, their psychological states change systematically due to factors such as practice, learning, and/or boredom. However, the dominant frameworks for modeling cognitive processes, such as evidence accumulation models, only consider a single estimate of a process across the duration of an experiment. Our study describes, develops, and assesses the ParAcT-DDM framework: the Par ameters Ac ross T ime D iffusion D ecision M odel, which unifies previous modeling efforts from practice and decision-making research. Specifically, our framework models time-varying changes to diffusion decision model parameters by assuming that rather than being constant across time, their estimates follow theoretically informed time-varying (e.g., trial-varying or block-varying) functions. Focusing on two diffusion model parameters: drift rate (task efficiency) and threshold (caution), our empirical results show that ParAcT-DDM variants vastly outperform the standard diffusion model in four existing data sets, including one where participants completed a practice block before data recording began, suggesting that time-varying cognitive processes often occur in typical cognitive experiments, even when the experimental design explicitly tries to remove practice effects. Finally, we find that the existence of time-varying processes causes systematic biases in the parameter estimates of the standard diffusion model, suggesting that our ParAcT-DDM framework can be crucial to ensuring the robustness of inferences against time-varying changes, regardless of whether these changes are of direct interest. (PsycInfo Database Record (c) 2026 APA, all rights reserved).</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Attentional dynamics explain the elusive nature of context effects. 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The authors propose an attention-based framework where time spent comparing similar versus dissimilar options drives context effects (attraction, compromise, similarity); they show how display layout and attention constraints can reverse or nullify these effects and develop a continuous model to fit both choices and response times.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Trueblood, J., Liu, Y., Murrow, M., Hayes, W., Holmes, W.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.52</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1037/rev0000606' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1037/rev0000606</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Context effects in multialternative, multiattribute choice are pervasive and yet, paradoxically, elusive at the same time. For example, simple changes to the spatial layout of alternatives on the screen can nullify or reverse the effects. Despite the success of dynamic decision models in explaining the occurrence of context effects, a coherent theory for understanding their elusiveness is currently lacking. We introduce a novel theoretical framework that relies on attention-modulated comparisons to explain the elusive nature of context effects. We show through simulation that our model produces the attraction, compromise, and similarity effects simply by assuming that more time is spent comparing alternatives that are more similar. However, when more time is spent comparing dissimilar alternatives, model simulations reveal a reversal of the attraction and compromise effects. The empirical support for this model-based prediction is assessed by manipulating similarity-based attention in separate experiments for the three context effects (total N = 887). Further, by allowing the spatial organization of information to constrain the attention process, the model can explain changes in context effects induced by display layout. We show that the model&#39;s spatial attention mechanism allows it to capture presentation order effects in a reanalysis of previously published data. Finally, we develop a continuous approximation of the full model that permits fitting of choices and response times. In summary, the proposed framework provides a new tool for understanding not only the existence of context effects in choice, but also the attentional factors that lead to null or reversed context effects. (PsycInfo Database Record (c) 2026 APA, all rights reserved).</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Morbid curiosity as an adapted motivation to explore ambiguous but survival-relevant stimuli. 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>It reframes curiosity as an adaptive, uncertainty-reduction drive that prompts exploratory approach to ambiguous threats, proposing a cognitive/neurobiological model of information gathering that informs individual decision processes under uncertainty.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> March, D.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.43</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1037/rev0000613' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1037/rev0000613</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Morbid curiosity, or the seemingly paradoxical drive to engage with aversive or grotesque stimuli, has long puzzled psychologists, who have traditionally framed it as either a form of sensation-seeking or a mechanism for unambiguous threat learning. The current article proposes a novel adaptationist model positioning morbid curiosity as an evolved cognitive mechanism specifically tuned to resolve ambiguity surrounding survival-relevant stimuli. Drawing on evolutionary theory, cognitive psychology, and neurobiological evidence, I argue that morbid curiosity functions primarily as an uncertainty-reduction strategy, motivating individuals to approach ambiguous stimuli to clarify their threat or benefit. Unlike basic emotions such as fear or disgust that typically trigger immediate avoidance, morbid curiosity fosters cautious approach behaviors aimed at gathering survival-critical information. The proposed model thereby reconceptualizes morbid curiosity as an adaptive, ambiguity-oriented cognitive system, offering novel insights into broader questions about human motivation, information-seeking, and adaptive cognition. (PsycInfo Database Record (c) 2026 APA, all rights reserved).</span>
                </div>
              </div>
            </div>
            
        <a id="journal-journal-of-economic-psychology"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        Journal of Economic Psychology
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Paying none, some or all? Between-subject random incentives and preferences towards risk and time 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>Investigates how randomizing incentives across subjects influences individuals&#39; risk and time preferences, contributing to measurement and cognitive aspects of choice under uncertainty.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Berlin, N., Kemel, E., Lenglin, V., Nebout, A.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.5</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1016/j.joep.2025.102870' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1016/j.joep.2025.102870</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">International audience</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Outcome bias in managerial decisions 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>Examines outcome bias in managerial decisions, showing how outcomes bias judgments of decision quality and revealing the cognitive processes underlying this bias.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> van Ours, J.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.41</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1016/j.joep.2025.102872' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1016/j.joep.2025.102872</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Not available.</span>
                </div>
              </div>
            </div>
            
        <a id="journal-management-science"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        Management Science
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Human–Algorithmic Bias: Source, Evolution, and Impact 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The study analyzes how individual evaluators make loan decisions, identifying source and evolution of biases in a repeat-decision context, using a structural econometric model, and examines how bias interacts with ML approaches to affect fairness and outcomes.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Hu, X., Huang, Y., Li, B., Lu, T.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.49</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2022.03862' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2022.03862</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Prior work on human-algorithmic bias has seen difficulty in empirically identifying the underlying mechanisms of bias because in a typical “one-time” decision-making scenario, different mechanisms generate the same patterns of observable decisions. In this study, leveraging a unique repeat decision-making setting in a high-stakes microlending context, we aim to uncover the underlying source, evolution dynamics, and associated impacts of bias. We first develop a structural econometric model of the decision dynamics to understand the source and evolution of bias in human evaluators in microloan granting. We find that both preference-based and belief-based biases exist in human decisions and are in favor of female applicants. Our counterfactual simulations show that the elimination of either of the two biases improves the fairness in financial resource allocation as well as the platform profits. The profit improvement mainly stems from the increased approval probability for male borrowers, especially those who would eventually pay back loans. Furthermore, to examine how human biases evolve when being inherited by machine learning (ML) algorithms, we train state-of-the-art ML algorithms for default risk prediction on both real-world data sets with human biases encoded within and counterfactual data sets with human biases partially or fully removed. We find that even fairness-unaware ML algorithms can reduce bias in human decisions. Interestingly, although removing both types of human bias from the training data can further improve ML fairness, the fairness-enhancing effects vary significantly between new and repeat applicants. Based on our findings, we discuss how to reduce decision bias most effectively in a human-ML pipeline. This paper was accepted by D. J. Wu, Special Issue on the Human-Algorithm Connection. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.03862 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Till Tech Do Us Part: Betrayal Aversion and Its Role in Algorithm Use 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>An experiment shows betrayal aversion toward human advisors reduces willingness to delegate to them but not toward algorithms, producing lower earnings in the human-advisor condition—highlighting how cognitive representations of trust influence individual risk decisions.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Kormylo, C., Adjerid, I., Ball, S., Dogan, C.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.48</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2022.03510' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2022.03510</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Failing to follow expert advice can have real and dangerous consequences. While any number of factors may lead a decision maker to refuse expert advice, the proliferation of algorithmic experts has further complicated the issue. One potential mechanism that restricts the acceptance of expert advice is betrayal aversion, or the strong dislike for the violation of trust norms. This study explores whether the introduction of expert algorithms in place of human experts can attenuate betrayal aversion and lead to higher overall rates of seeking expert advice. In other words, we ask: are decision makers averse to algorithmic betrayal? The answer to this question is uncertain ex ante. We answer this question through an experimental financial market where there is an identical risk of betrayal from either a human or algorithmic financial advisor. We find that the willingness to delegate to human experts is significantly reduced by betrayal aversion, while no betrayal aversion is exhibited toward algorithmic experts. The impact of betrayal aversion toward financial advisors is considerable: the resulting unwillingness to take the advice of the human expert leads to a 20% decrease in subsequent earnings, while no loss in earnings is observed in the algorithmic expert condition. This study has significant implications for firms, policymakers, and consumers, specifically in the financial services industry. This paper was accepted by D. J. Wu, Special Issue on the Human-Algorithm Connection. Funding: This work was supported by National Science Foundation [Grant 1541105]. Supplemental Material: The data files are available at https://doi.org/10.1287/mnsc.2022.03510 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Humans’ Use of AI Assistance: The Effect of Loss Aversion on Willingness to Delegate Decisions 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>Loss framing reduces algorithm aversion and equalizes delegation to AI and humans across tasks of differing complexity, with increased situational awareness identified as the mechanism.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Bockstedt, J., Buckman, J.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.46</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2024.05585' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2024.05585</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">As artificial intelligence (AI) tools have become pervasive in business applications, so too have interactions between AI and humans in business processes and decision-making. A growing area of research has focused on human decision and task delegation to AI assistants. Simultaneously, extensive research on algorithm aversion—humans’ resistance to algorithm-based decision tools—has demonstrated potential barriers and issues with AI applications in business. In this paper, we test a simple strategy for mitigating algorithm aversion in the context of AI task delegation. We show that simply changing the framing of decision tasks can allay algorithm aversion. Through multiple studies, we found that participants exhibited a strong preference for human assistance over AI assistance when they were rewarded for task performance (i.e., money was gained for good performance), even when the AI had been shown to outperform the human assistant on the task. Alternatively, when we reframed the task such that the participant experienced losses for poor performance (i.e., money was taken from their endowment for poor performance), the bias for preferring human assistance was removed. Under loss framing, participants delegated the decision task to human and AI assistants at similar rates. We demonstrate this finding across tasks at differing levels of complexity and at different incentive sizes. We also provide evidence that loss framing increases situational awareness, which drives the observed effects. Our results offer useful insights on reducing algorithm aversion that extend the literature and provide actionable suggestions for practitioners and managers. This paper was accepted by Dongjun Wu, Special Issue on the Human-Algorithm Connection. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2024.05585 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Trading Gamification and Investor Behavior 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>An online randomized experiment shows that hedonic gamification on trading platforms increases activity mainly through self-selection; gamification is associated with noisier trading among some users and interacts with users&#39; beliefs and price signals to affect learning and trading quality.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Chapkovski, P., Khapko, M., Zoican, M.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.46</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2022.02650' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2022.02650</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">We study the effect of gamification on retail traders’ behavior using a randomized online experiment. Participants with lower financial literacy prefer platforms with hedonic gamification elements, such as confetti and achievement badges. On average, hedonic gamification increases trading volume by 5.17%. However, the difference in trading activity between gamified and nongamified platforms is driven primarily by self-selection (70%) rather than gamification (30%). Participants who prefer hedonic gamification exhibit noisy trading strategies, whereas those favoring nongamified platforms display stronger contrarian behavior. Further, price trend notifications enhance learning for investors with accurate beliefs, but they reinforce trading mistakes for those with incorrect beliefs. This paper was accepted by Jean-Edouard Colliard, Special Issue on the Human-Algorithm Connection. Funding: P. Chapkovski acknowledges funding from the Deutsche Forschungsgemeinschaft [Germany’s Excellence Strategy—EXC 2126/1-390838866]. M. Khapko and M. Zoican acknowledge the Social Sciences and Humanities Research Council of Canada [Insight Development Grant 430-2018-00125] and the Canadian Securities Institute Research Foundation [research grant]. M. Zoican acknowledges financial support from the Quantitative Management Research Initiative (QMI) under the aegis of the Fondation du Risque, a joint initiative by Université Paris-Dauphine, l’École Nationale de la Statistique et de l’Administration ParisTech, and LFIS, France. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.02650 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Managerial Insight and “Optimal” Algorithms 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>It introduces a flexible managerial-insight model and the FIND method for turning forecasts into probabilistic demand representations, and shows through eight experiments that this approach improves ordering performance across diverse signals, including perceptual inputs.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Flicker, B.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.45</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2022.03919' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2022.03919</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Work is increasingly being completed by humans and algorithms in collaboration. A relative strength of humans in this partnership is their insight: private information that is relevant to the task but not available to computerized systems. I introduce a flexible model of managerial insight that accepts any distribution of demand, an advantage over alternative models, and apply it to the newsvendor setting. The optimal policy in this setting is theoretically straightforward but difficult for managers to implement directly. I propose a novel method called FIND that leverages historical forecasts to convert a point estimate of demand into a conditional probability distribution. In eight experiments, FIND outperforms all other ordering regimes considered over a broad range of conditions. To model subtle, unstructured demand signals, the last four experiments convey managerial insight nonquantitatively using images, colors, and tones. FIND performs equally well with these perceptual signals as it does with more traditional numerical signals. This paper was accepted by Felipe Caro, Special Issue on the Human-Algorithm Connection. Funding: This research was supported by the National Science Foundation (Award No. 1729837) and the Research Grant Program of the Darla Moore School of Business, University of South Carolina. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.03919 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Using AI and Behavioral Finance to Cope with Limited Attention and Reduce Overdraft Fees 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>A field experiment tests AI-assisted reminders to prevent overdrafts, focusing on how message simplicity and framing affect individuals&#39; decisions under limited attention, using time-to-event analyses to capture process-level effects.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Ben-David, D., Mintz, I., Sade, O.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.45</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2022.00304' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2022.00304</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">We test how effective a human–algorithm interaction is at stopping users from overdrawing their bank accounts. We use a randomized field experiment and draw our sample from users of a large personal financial management platform operating in the United States and Canada. We find that sending as-needed reminders is effective in and of itself, and the impact is intensified by the human response to the structure of the message. More simple messages are more effective, and the framing of the simplified message makes a difference. Users with medium to high annual incomes and users with fair to good credit scores are most likely to respond positively. We find that the investigated artificial intelligence solution reduces information-gathering costs and has a positive effect but is not sufficient in all cases. Those with challenging financial situations may find it harder to act upon the warning. For our analysis, we employ parametric identifications and time-to-event semiparametric analysis. Our work contributes to the literature on financial technology as advisors, human–computer interaction, limited attention, behavioral finance, and experimental finance. This paper was accepted by Jean-Edouard Colliard, Special Issue on the Human-Algorithm Connection. Funding: O. Sade acknowledges financial support for this research from the Krueger Center and the Albertson-Waltuch Chair in Business Administration. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.00304 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Is Your Machine Better Than You? You May Never Know 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>It studies how a human supervisor learns about an AI system&#39;s performance across repeated tasks and when they choose to trust or override the machine, highlighting the cognitive processes and biases that shape decision making under uncertainty.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> de Véricourt, F., Gurkan, H.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.44</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2023.4791' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2023.4791</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Artificial intelligence systems are increasingly demonstrating their capacity to make better predictions than human experts. Yet recent studies suggest that professionals sometimes doubt the quality of these systems and overrule machine-based prescriptions. This paper explores the extent to which a decision maker (DM) supervising a machine to make high-stakes decisions can properly assess whether the machine produces better recommendations. To that end, we study a setup in which a machine performs repeated decision tasks (e.g., whether to perform a biopsy) under the DM’s supervision. Because stakes are high, the DM primarily focuses on making the best choice for the task at hand. Nonetheless, as the DM observes the correctness of the machine’s prescriptions across tasks, the DM updates the DM’s belief about the machine. However, the DM is subject to a so-called verification bias such that the DM verifies the machine’s correctness and updates the DM’s belief accordingly only if the DM ultimately decides to act on the task. In this setup, we characterize the evolution of the DM’s belief and overruling decisions over time. We identify situations under which the DM hesitates forever whether the machine is better; that is, the DM never fully ignores but regularly overrules it. Moreover, the DM sometimes wrongly believes with positive probability that the machine is better. We fully characterize the conditions under which these learning failures occur and explore how mistrusting the machine affects them. These findings provide a novel explanation for human–machine complementarity and suggest guidelines on the decision to fully adopt or reject a machine. This paper was accepted by Elena Katok, Special Issue on the Human-Algorithm Connection. Supplemental Material: The online appendix is available at https://doi.org/10.1287/mnsc.2023.4791 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Incentives, Framing, and Reliance on Algorithmic Advice: An Experimental Study 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>An experimental study showing that compensation design and framing of an AI algorithm modulate how much decision makers rely on algorithmic advice and how long they invest in the task; framing the algorithm as incorporating human expertise increases advice use, especially under fixed-pay conditions.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Greiner, B., Grünwald, P., Lindner, T., Lintner, G., Wiernsperger, M.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.43</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2022.02777' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2022.02777</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Managerial decision makers are increasingly supported by advanced data analytics and other artificial intelligence (AI)-based technologies, but they are often found to be hesitant to follow the algorithmic advice. We examine how compensation contract design and framing of an AI algorithm influence decision makers’ reliance on algorithmic advice and performance in a price estimation task. Based on a large sample of almost 1,500 participants, we find that compared with a fixed compensation, both compensation contracts based on individual performance and tournament contracts lead to an increase in effort duration and to more reliance on algorithmic advice. We further find that using an AI algorithm that is framed as also incorporating human expertise has positive effects on advice utilization, especially for decision makers with fixed pay contracts. By showing how widely used control practices, such as incentives and task framing, influence the interaction of human decision makers with AI algorithms, our findings have direct implications for managerial practice. This paper was accepted by David Simchi-Levi, Special Issue on the Human-Algorithm Connection. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.02777 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Human-Robot Interactions in Investment Decisions 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>A field study showing robo-advisors increase investor attention and rebalancing toward target allocations, leading to higher returns, with automatic rebalancing offering only modest extra gains, illustrating human-in-the-loop decision processes under uncertainty.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Bianchi, M., Brière, M.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.43</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2022.03886' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2022.03886</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">We study the introduction of robo-advising on a large set of employee saving plans. Different from many services that fully automate portfolio decisions, our robo-advisor proposes investment and rebalancing strategies, leaving investors free to follow or ignore them. The resulting human-robot interactions occur both at the time of the subscription and over time, as the robot sends alerts when the investor’s portfolio gets too far from the target allocation. We show that the robo-service is associated with an increase in investors’ attention and trading activities. Following the robot’s alerts, investors change their rebalancing behaviors so as to stay closer to their target allocation, which results in larger portfolio returns. Counterfactual returns induced by automatic rebalancing by the robot would be only slightly higher, suggesting that, on average, the financial cost of letting investors retain control is not large. This paper was accepted by Jean-Edouard Colliard, Special Issue on the Human-Algorithm Connection. Funding: This work was supported by Observatoire epargne europeenne, as well as LTI@Unito and Agence Nationale de la Recherche [Grant ANR-17-EURE-0010] to M. Bianchi. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.03886 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Behavioral Externalities of Process Automation 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The paper experimentally examines how upstream vs downstream automation and human–robot collaboration affect individual and joint decision making, productivity, and deviations from optimal policies, finding automation generally improves completion rates and times but interactions depend on task placement and social preferences.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Beer, R., Qi, A., Rios, I.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.42</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2024.05408' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2024.05408</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">We study the behavioral effects of process automation on human workers interacting with automated tasks. We introduce a stylized normative model with two workers who complete their tasks sequentially, working toward a joint project to obtain a fixed payment plus a variable bonus that depends on how early the project is completed. The normative model prescribes that, if workers are fully rational, they will complete their tasks as soon as possible if the early completion bonus is high enough. However, following the literature, we hypothesize that workers will suboptimally delay project completion. Following the insights from a behavioral model, we further predict that automation will alleviate this problem by reducing strategic uncertainty, resulting in an indirect behavioral benefit of a higher worker productivity, in addition to the direct benefit of a higher project completion rate and a shorter project duration. To test these predictions, we conduct an experiment replicating the theoretical model, varying (i) whether a worker collaborates with a coworker or a robot, and (ii) in the case of collaborating with a robot, whether the upstream or downstream task is the one automated. First, we find that workers largely deviate from the optimal policy, as they take longer than what the normative theory prescribes to complete their tasks or do not complete the project. Second, we show that process automation increases the project completion rate and reduces the project completion time, confirming the benefits of process automation. Interestingly, workers who collaborate with robots take longer to complete their tasks, contradicting our initial hypothesis that process automation has a positive effect on the productivity of human workers. In addition, we find that upstream automation is more beneficial than downstream automation. We also show that social preferences are an important driver of these results because prosocial subjects tend to be more productive when collaborating with a human coworker than with a robot. Finally, we show that our findings remain robust in a continuous processing setting. This paper was accepted by Felipe Caro, Special Issue on the Human-Algorithm Connection. Funding: The authors gratefully acknowledge financial support from Zicklin School of Business, Baruch College, the City University of New York, and the University of Texas at Dallas. Support for this project was provided by a PSC-CUNY Award, jointly funded by the Professional Staff Congress and the City University of New York. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2024.05408 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Algorithm Reliance: Fast and Slow 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>A laboratory study showing that algorithm quality and system load shape whether workers follow the algorithm&#39;s advice and how quickly they decide; speed benefits emerge mainly when advice is used, with deliberation influencing throughput—highlighting cognitive processes in algorithm-assisted individual decision making.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Snyder, C., Keppler, S., Leider, S.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.4</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2023.01989' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2023.01989</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">In algorithm-augmented service contexts where workers have decision authority, they face two decisions about the algorithm: whether to follow its advice and how quickly to do so. The pressure to work quickly increases with the speed of arriving customers. In this paper, we ask the following. How do workers use algorithms to manage system loads? With a laboratory experiment, we find that superior algorithm quality and high system loads increase participants’ willingness to use their algorithm’s advice. Consequently, participants with the superior algorithm make higher-quality recommendations than those with no algorithm (participants with the inferior algorithm make slightly lower-quality recommendations than those without). However, participants do not necessarily speed up by using algorithms’ advice; their throughput times only decrease compared with the no-algorithm baseline when the system load is high and algorithm quality is superior, although participants would benefit from working faster in all treatments. This happens in part because participants in the high-load, superior-algorithm treatment serve customers more quickly than participants in the other treatments, conditional on using the algorithm. Participants in the high-load, superior-algorithm treatment work especially quickly in later periods as they increasingly default to their algorithm’s advice. Our findings show that algorithms can have benefits for both decision quality and speed. Quality benefits come from workers’ decision to use their algorithms’ advice, whereas speed benefits depend on workers’ algorithm use and the time they spend deliberating about their algorithm use. Ultimately, algorithm quality and system load are mutually reinforcing factors that influence both service quality and especially speed. This paper was accepted by Elena Katok, Special Issue on the Human-Algorithm Connection. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2023.01989 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Human-Algorithm Collaboration with Private Information: Naïve Advice-Weighting Behavior and Mitigation 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The paper documents a naive advice-weighting (NAW) bias in how people blend their own information with algorithm output in demand forecasting, showing this bias harms accuracy. It demonstrates that feature transparency and training can help people rely more on private information and improve performance.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Balakrishnan, M., Ferreira, K., Tong, J.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.39</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2022.03850' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2022.03850</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Even if algorithms make better predictions than humans on average, humans may sometimes have private information that an algorithm does not have access to that can improve performance. How can we help humans effectively use and adjust recommendations made by algorithms in such situations? When deciding whether and how to override an algorithm’s recommendations, we hypothesize that people are biased toward following naïve advice-weighting (NAW) behavior; they take a weighted average between their own prediction and the algorithm’s prediction, with a constant weight across prediction instances regardless of whether they have valuable private information. This leads to humans overadhering to the algorithm’s predictions when their private information is valuable and underadhering when it is not. In an online experiment where participants were tasked with making demand predictions for 20 products while having access to an algorithm’s predictions, we confirm this bias toward NAW and find that it leads to a 20%–61% increase in prediction error. In a second experiment, we find that feature transparency—even when the underlying algorithm is a black box—helps users more effectively discriminate how to deviate from algorithms, resulting in a 25% reduction in prediction error. We make further improvements in a third experiment via an intervention designed to move users away from advice weighting and instead, use only their private information to inform deviations, leading to a 34% reduction in prediction error. This paper was accepted by Elena Katok, Special Issue on the Human-Algorithm Connection. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.03850 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Strategic Inattention in Product Search 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The paper investigates strategic inattention in online product search, showing how consumers trade off extensive search (better fit) against potentially worse deals due to data-driven price discrimination. It combines theory and experiments to assess welfare and regulatory implications.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Hillenbrand, A., Hippel, S.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.39</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2022.03413' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2022.03413</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Rapid technological developments in online markets fundamentally change the relationship between consumers and sellers. Online platforms can easily gather data about consumers’ search behavior, allowing for price discrimination. Therefore, product search becomes a strategic choice. Consumers face a tradeoff: Search intensely and receive a better fit at a potentially higher price or restrict search behavior, be strategically inattentive, and receive a worse fit but maybe a better deal. We study the resulting strategic buyer-seller interaction theoretically and experimentally. Our experimental results shed a critical light on the added value for consumers through the rise of online platforms and on the effectiveness of current regulations. This paper was accepted by Elena Katok, Special Issue on the Human-Algorithm Connection. Funding: This work was supported by the ZEW–Leibniz-Zentrum für Europäische Wirtschaftsforschung, and the Max-Planck-Gesellschaft. Supplemental Material: The data files are available at https://doi.org/10.1287/mnsc.2022.03413 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                The Power of Disagreement: A Field Experiment to Investigate Human–Algorithm Collaboration in Loan Evaluations 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>A field-experiment study of human–algorithm collaboration in loan evaluations, investigating how disagreement between humans and algorithms affects decision quality under different information regimes, highlighting the role of cognitive processes in collaborative decisions.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Wang, H., Zhang, Y., Lu, T.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.39</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2022.03844' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2022.03844</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Human–algorithm collaboration is becoming increasingly prevalent in the economy and society. However, this collaboration is not always fruitful, and in extreme cases, people become human borgs or totally averse to algorithms. The key to collaborative value is whether humans and algorithms can complement each other in decision making, but it is challenging for humans to disagree with algorithmic recommendations at the right time (i.e., to disagree when algorithms are wrong and not disagree when algorithms are right). To understand the centric role of disagreement in human–algorithm collaboration and examine when and how it benefits, we conducted a field experiment in which human evaluators and algorithms worked together to evaluate loan applications under four scenarios, that is, limited/rich information and with/without disclosure of algorithm rationale. Our results show that human–algorithm collaboration decisions outperformed human- or algorithm-only decisions, and these collaborative values varied across the four scenarios. We further propose a theoretical framework for mechanism examination that centers on the formation and effectiveness of disagreement. We validate the framework empirically and come to the following findings: (1) disagreement exhibits a sizable and nonlinear influence on collaborative value, (2) the differences between human evaluators and algorithms in decision making contribute to disagreement but not to collaborative value, (3) algorithm self-contradiction triggers disagreement and helps human evaluators disagree with algorithms at the right time. These findings provide valuable theoretical insights on how collaborative value is achieved and managerial insights on how to manage disagreement in human–algorithm collaboration. This paper was accepted by Hemant Bhargava, Special Issue on the Human-Algorithm Connection. Funding: Y. Zhang appreciates the support from the National Natural Science Foundation of China [Grant 72272003]. Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.03844 .</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Aversion to Hiring Algorithms: Transparency, Gender Profiling, and Self-Confidence 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>An online experiment examining when workers and managers prefer or distrust hiring algorithms, how transparency affects those choices, and how gender profiling and overconfidence influence delegation decisions.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Dargnies, M., Hakimov, R., Kübler, D.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.38</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1287/mnsc.2022.02774' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1287/mnsc.2022.02774</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">We run an online experiment to study the origins of algorithm aversion. Participants are in the role of either workers or managers. Workers perform three real-effort tasks: task 1, task 2, and the job task, which is a combination of tasks 1 and 2. They choose whether the hiring decision between themselves and another worker is made by a participant in the role of a manager or by an algorithm. In a second set of experiments, managers choose whether they want to delegate their hiring decisions to the algorithm. When the algorithm does not use workers’ gender to predict their job-task performance and workers know this, they choose the algorithm more often than in the baseline treatment where gender is employed. Feedback to the managers about their performance in hiring the best workers increases their preference for the algorithm relative to the baseline without feedback, because managers are, on average, overconfident. Finally, providing details on how the algorithm works does not increase the preference for the algorithm for workers or for managers. This paper was accepted by Elena Katok, Special Issue on the Human-Algorithm Connection. Funding: D. Kübler acknowledges financial support from the Deutsche Forschungsgemeinschaft [CRC TRR 190], R. Hakimov acknowledges financial support from the Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung [Project 100018_189152], and M.-P. Dargnies acknowledges financial support from the Agence Nationale de la Recherche (ANR JCJC TrustSciTruths). Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mnsc.2022.02774 .</span>
                </div>
              </div>
            </div>
            
        <a id="journal-cognitive-psychology"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        Cognitive Psychology
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Errors, fast and slow 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>Across 20 datasets, it validates a simple nonparametric model that predicts when errors are faster or slower than correct responses in generalized conflict tasks, attributing effects to the interaction/alignments of multiple processes and offering testable hypotheses about process multiplicity.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Alós-Ferrer, C., Alós-Ferrer, C., Garagnani, M.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.47</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1016/j.cogpsych.2025.101779' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1016/j.cogpsych.2025.101779</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">© 2025 The AuthorsHuman errors in cognitive, attentional, and decision-making tasks are sometimes faster than correct responses, and sometimes slower, even for the same fixed task and experimental implementation. Several existing models can fit response time distributions exhibiting these phenomena. However, it is hard to predict ex ante (i.e., before data collection) when errors will be fast or slow. Relying on 20 different datasets comprising 31 experiments from different domains, we empirically validate a simple nonparametric model which successfully predicts when errors will be faster or slower than correct responses. The predictions also include a generalized Stroop effect, as well as error rate differences. The model applies to generalized conflict tasks, where the interaction of multiple processes determines behavior, and makes predictions which depend on whether those processes are in alignment or conflict in a given trial, which can be determined before data collection (e.g., congruent vs. incongruent trials). This yields new testable hypotheses which are overwhelmingly supported in the data. The model&#39;s predictions can also be seen as a test of whether process multiplicity is a reasonable assumption in a given task.</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Compressed representations and attentional competition in numeric integration for average estimations 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The study tests two theories of how people combine numbers from one or two streams to estimate averages, finding overall underestimation and limited impact from competing information; it uses computational models to compare theories and to quantify integration noise, highlighting the cognitive processes involved in sequential numeric information integration.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Sun, Y., Sun, Y., Olschewski, S., Mason, A., Olschewski, S.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.38</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1016/j.cogpsych.2025.101780' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1016/j.cogpsych.2025.101780</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">© 2025 The AuthorsThe ability to gauge the average of a number stream is a fundamental aspect of numeric cognition, information processing, and value-based decisions. Research on this ability has primarily focused on the integration of numerical information from a single source. Here, we examined the estimation of averages when competing sources of information are presented. We tested two theories of numeric value integration: the Compressed Mental Number Line (CMNL) predicts underestimation of averages independent of competing information; Selective Integration (SI) predicts that competing information interferes with the target information. Across four experiments, we found significant underestimation of averages in both single- and dual-stream conditions, and a limited impact of competing information on estimation. Computational modeling showed that the CMNL provides the overall better account than SI to describe estimation behavior in our data. However, about one-third of our participants were best described by SI. We also modeled the integration noise of the CMNL and found that this noise increased in the dual- compared to the single-stream conditions without affecting the representational compression. Overall, our findings clarify the role of competing information in average estimations, discover limitations in processing multiple streams, and shed light on the cognitive processes underlying sequential information integration.</span>
                </div>
              </div>
            </div>
            
        <a id="journal-journal-of-experimental-psychology-learning-memory-and-cognition"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        Journal of Experimental Psychology: Learning, Memory, and Cognition
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Testing the convergent validity of the nondecision time parameter of the diffusion model. 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The paper tests the convergent validity of the nondecision time parameter (t0) in diffusion models using encoding difficulty manipulations in lexical decision tasks, finding strong effects on t0 and spillovers to drift rate and starting point, with simulations suggesting limitations in discriminant validity under certain assumptions.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Pollak, K., Lerche, V., Hartmann, R., Kiesel, A.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.46</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1037/xlm0001566' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1037/xlm0001566</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Modeling reaction time data using diffusion models comes with the advantage of separating different processes involved in decision making. Each parameter of the diffusion model is assumed to translate into one (or more) process(es). If this assumption holds true, selective manipulations of specific processes involved in decision making should selectively influence the related parameter, but not any other parameter (high convergent and discriminant validities). We present two experiments (total N = 104) and one simulation study that-using a manipulation of the difficulty of encoding in a lexical decision task-tested the convergent validity of the nondecision time t ₀. As hypothesized, we found large effects on t ₀ in both experiments but also medium to large effects on the drift rate v as well as on the starting point z . Our simulation study suggests that the effects on the drift rate, but not on the starting point, might be explained by incorrect assumptions about the intertrial variability of the nondecision time. Our results speak in favor of a high convergent validity of t ₀ but question the discriminant validities of v and z , at least under the assumption that our manipulation affected encoding selectively. (PsycInfo Database Record (c) 2026 APA, all rights reserved).</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Probability cueing in large-scale environmental search: The role of landmark cues in statistical learning. 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>In immersive VR, participants learn and apply a probability cue for target location, with the presence/position of a landmark modulating cue use; results show learning and cueing depend on the landmark–distribution spatial relationship, illustrating how environmental structure shapes probabilistic search decisions at the individual level.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Dordoy, S., Baxter, R., Smith, A.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.38</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1037/xlm0001573' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1037/xlm0001573</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Efficient environmental search is an important and adaptive everyday skill. A particular feature of theoretical interest is whether large-scale search is informed by the spatial statistics of the environment-probability cueing is a robust effect in two-dimensional visual search tasks, but studies of large-scale search have generated equivocal findings. Here, we examined whether sensitivity to a statistical cue specified within an allocentric reference frame is modulated by the presence and location of environmental landmarks. Participants explored fully immersive virtual environments, wherein they were presented with an array of locations (columns) and required to search them for a hidden target (i.e., the column that changed color upon activation). A target was present on each trial, appearing within the cued hemispace on 80% of trials. In Experiment 1, the array was surrounded by a featureless circular wall, and participants exhibited no reliable cueing effects. Experiments 2 and 3 introduced a stable landmark into the environment and manipulated its location to be either orthogonal or adjacent to the cued hemispace. Participants reliably biased their search in response to the probability cue, although learning was only observed when the landmark was positioned along the axis orthogonal to the midline separating hemispaces. These findings suggest that adapting search behavior in response to a statistical cue is facilitated by the presence of a stable landmark when it is specified independently of the searcher&#39;s viewpoint, although this is dependent upon the spatial relationship between the landmark and the distribution itself. (PsycInfo Database Record (c) 2026 APA, all rights reserved).</span>
                </div>
              </div>
            </div>
            
        <a id="journal-trends-in-cognitive-sciences"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        Trends in Cognitive Sciences
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Structure uncovered: understanding temporal variability in perceptual decision-making 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The paper appears to study how timing fluctuations affect perceptual decisions, contributing to understanding of internal representations and decision processes at the individual level, likely with behavioral data and formal modeling.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Urai, A.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.45</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1016/j.tics.2025.06.003' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1016/j.tics.2025.06.003</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Not available.</span>
                </div>
              </div>
            </div>
            
        <a id="journal-psychological-science"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        Psychological Science
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Choice Set Size Neglect in Predicting Others’ Preferences 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>People underweight how the number of available options influences predicted liking for a chosen option, but this neglect decreases when attention to set size is increased or when framing shifts (e.g., ranking vs choosing), illustrating how informational complexity shapes attribution about others&#39; preferences.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Hu, B., Moon, A., VanEpps, E.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.44</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1177/09567976251400333' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1177/09567976251400333</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">An inherent feature of any choice is the set size from which that choice is made (i.e., the number of available options in a choice set). Choice set size impacts the likelihood of landing on a more preferred option: Larger sets are more likely to contain an option matching one’s preferences. Nevertheless, in six preregistered experiments with 10,092 U.S. adults, we demonstrated that people consistently underestimated the effect of set size when predicting others’ liking for a chosen option. We propose this effect arises because, although people recognize that set size predicts liking of a chosen option, they typically fail to attend to it when considering others’ choices. Accordingly, this effect was attenuated when attention was drawn to set size, specifically (a) when participants considered multiple set sizes simultaneously, (b) when the decision process was framed as ranking rather than choosing, or (c) when participants were prompted to recall set size before predicting others’ preferences.</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Understanding Partisan Bias in Judgments of Misinformation: Identity Protection Versus Differential Knowledge 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>It shows that people are more likely to accept information aligned with a randomly assigned identity, supporting identity-protection explanations for misinformation judgments over knowledge differences.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Hubeny, T., Nahon, L., Gawronski, B.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.37</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1177/09567976251404040' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1177/09567976251404040</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">People overaccept information that supports their identity and underaccept information that opposes their identity—a phenomenon known as partisan bias . Although partisan-bias effects in judgments of misinformation are robust and pervasive, there is ongoing debate about whether partisan-bias effects arise from identity-protective motivated reasoning or differential knowledge of identity-congenial versus identity-uncongenial information. Prior empirical work has been unable to differentiate the two accounts because of a reliance on groups with pre-existing differences in knowledge (e.g., Democrats and Republicans). The current research addresses this issue by using randomly assigned rather than pre-existing identities. Across two experiments ( N total = 1,411), adult U.S. Prolific workers showed lower thresholds for accepting information that is congenial versus uncongenial to a randomly assigned identity, despite having no differences in prior knowledge. These results support theories that emphasize identity protection as a factor underlying partisan bias in the acceptance of misinformation, with important practical implications for misinformation interventions.</span>
                </div>
              </div>
            </div>
            
        <a id="journal-journal-of-behavioral-decision-making"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        Journal of Behavioral Decision Making
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Intertemporal Impatience Across Mental Health in a Community Sample: A Novel Transdiagnostic Approach 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The study analyzes how intertemporal impatience relates to mental-health–related behaviors in a community sample, identifying a transdiagnostic impulsivity dimension and dissecting symptom-level drivers of impatience.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Burghoorn, F., Roelofs, K., Burk, W., Jorgensen, T., Scheres, A., Figner, B.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.43</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1002/bdm.70056' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1002/bdm.70056</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">ABSTRACT Intertemporal impatience has been proposed to be centrally and transdiagnostically implicated across mental health difficulties, including maladaptive behaviors, psychopathologies, and other psychological outcomes. We empirically tested this proposal using a novel research approach that integrates per‐category , trans‐category , scale‐level , and item‐level analyses. First, we studied per‐category continuous associations between intertemporal impatience and a broad range of mental health‐related behaviors and psychological constructs. Next, we examined which of several latent, trans‐category dimensions were associated with impatience, thereby studying which mental health difficulties may be connected through shared impatience. Finally, we investigated which specific symptoms or behaviors were driving these associations. This study was conducted in a community sample of 899 participants who completed an intertemporal choice task and various self‐report mental health measures. Per‐category analyses involved bivariate correlations and multiple regressions; trans‐category analyses involved exploratory factor analyses to identify transdiagnostic dimensions, and structural‐after‐measurement models to test for associations between the dimensions and intertemporal impatience. Intertemporal impatience was associated with increased nicotine use, reactive aggression, non‐planning impulsivity, motor impulsivity, and dispositional greed. Moreover, impatience was positively associated with a transdiagnostic impulsivity dimension (including attention‐deficit/hyperactivity disorder, low self‐control, and motor and non‐planning impulsivity). Symptom‐level analyses suggested that this association was mainly driven by information impulsivity (also known as lack of premeditation) and financial impulsivity. Our results provide support for the role of intertemporal impatience across several externalizing but not internalizing mental health difficulties and offer a detailed and nuanced interpretation of the transdiagnostic role of intertemporal impatience across mental health.</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Information on Judgment Invariance Influences Contributors&#39; Opting‐In Behavior in Sequential Collaboration 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The study shows that greater judgment invariance information lowers both the probability and the amount of judgment updates in sequential collaboration, with varying evidence for an expertise interaction, highlighting cognitive update processes in individual decision making under uncertainty.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Fischer, V., Mayer, M., Kimmerle, J.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.39</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1002/bdm.70063' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1002/bdm.70063</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">ABSTRACT Sequential collaboration describes an aggregation process intensively researched for numerical judgments which is characterized by a first contributor creating a judgment that is subsequently adjusted or maintained by following contributors. In previous research, participants performing sequential collaboration were only provided with information about the judgment of the person immediately preceding them in a sequential chain. However, in real‐world collaborative projects (e.g., Wikipedia and Google Docs projects), more information about the past development of a sequential chain is often accessible or even directly displayed. As a concise piece of such information, we used judgment invariance, that is, the number of times a current judgment remained unchanged in the immediately preceding steps of a sequential chain. We hypothesized that increasing judgment invariance decreases both the probability and the magnitude of participants&#39; judgment changes. Additionally, we hypothesized that the influence would be weakened with increasing expertise of participants. In three preregistered experiments, (G)LMM analyses suggested that increasing judgment invariance decreased the probability and magnitude of judgment changes confirming our hypothesized main effects. Concerning the interaction hypothesis of judgment invariance and expertise, a more ambiguous picture emerged. Experiment 1 was completely consistent with the interaction hypothesis. Experiment 2 supported it concerning the probability but not the magnitude of participants&#39; judgment changes. In Experiment 3, a directionally reversed interaction effect was observed, possibly due to unconscientious participation. We conclude that the insight into the past development of a sequential chain, specifically information on judgment invariance, influences the judgment behavior of contributors in sequential collaborations. In summary, judgment invariance could be established as a substantial influence in sequential collaboration, which comes with practical implications for real‐world collaborative projects.</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Who Is Afraid of the Pink Elephant? Evidence on (Not) Ignoring Inadmissible Evidence and Debiasing Interventions 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>The study uses online vignette experiments to test how inadmissible evidence (character vs. wiretap) biases verdicts and whether four debiasing interventions can mitigate this bias; wiretap evidence strongly biases judgments, and interventions reduce but do not fully eliminate bias.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Engel, C., Golder, J., Rahal, R.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.35</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1002/bdm.70064' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1002/bdm.70064</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">ABSTRACT People are often unable or unwilling to ignore thoughts they should disregard. This issue is particularly problematic in legal contexts, where defendants should be judged on the merits of the case, not on prejudice, rumors, or evidence obtained through questionable methods. This is why criminal law of procedure regulates which information can be introduced in a trial. In a series of online vignette experiments involving 1432 US participants, we examine the biasing impact of two types of inadmissible evidence: prior convictions (character evidence) and wiretap confessions. We failed to show that character evidence biases jurors&#39; judgments of the defendant&#39;s guilt, whereas wiretap evidence had a strong effect. We also assess the effectiveness of four debiasing interventions aimed at helping jurors ignore inadmissible evidence. While these interventions reduced bias, they did not fully eliminate it. These results provide nuance in the debate about information in the courtroom that should be suppressed.</span>
                </div>
              </div>
            </div>
            
        <a id="journal-jep-general"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        JEP: General
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Three international studies on pure coordination games: Adaptable solutions when intuitions are presumed to vary. 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>Across three international studies, participants coordinated on different answers without communication, with evidence that anticipation of others&#39; responses and content of reasoning drive coordination beyond simple salience, illustrating adaptive, content-rich individual decision processes.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Perez-Zapata, D., Isoni, A., Zawidzki, T., Apperly, I.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.39</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1037/xge0001876' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1037/xge0001876</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">In pure coordination games, players aim to give the same response without communication. Cognitive science research has focused on the reasoning and common knowledge necessary as the background conditions for coordination, with less attention paid to the challenge of intuiting responses on which coordination might be possible. Most studies have examined coordination within university samples from a single country, and so the extent of the challenge of coordinating between heterogeneous groups of people may have been underestimated. We conducted three empirical studies (two preregistered) with participants from the United Kingdom, South Africa, and Chile, plus a globally distributed sample (total N = 520). Without communicating, participants were asked to coordinate on answers to simple questions such as &quot;name a city.&quot; All groups coordinated at rates far above chance but often coordinated on different responses. Study 1 showed that participants from one group could nevertheless anticipate the responses of another group, while Studies 2 and 3 showed that participants could coordinate with a partner from a different group. Crucially, between-group partners most often coordinated on new responses that were rarely considered for within-group coordination, providing the strongest evidence to date to support Schelling&#39;s claim that coordination requires distinctive reasoning, beyond primary and secondary salience. These findings provide evidence that coordination decisions are variable and flexible, resulting in accurate adaptations to achieve coordination. Where previous work has focused predominantly on the forms of reasoning that support coordination, the present findings suggest that it is equally important to examine the content of coordination solutions. (PsycInfo Database Record (c) 2026 APA, all rights reserved).</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Choosing to believe: How active sampling enhances the truth effect. 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>Active information sampling intensifies the truth effect through processing-based mechanisms, showing that people’s beliefs are shaped by the information they choose to sample rather than only by passively encountered content.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Ingendahl, M., Schulte, A., Weber, F., Vaz, A., Woitzel, J., Alves, H.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.36</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1037/xge0001888' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1037/xge0001888</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Repeated exposure to information increases the credibility of this information, a well-studied phenomenon called the truth effect. While this phenomenon has been studied extensively by passively exposing people to preselected information pieces, in real-world contexts, people often sample information actively (e.g., by clicking on a headline on social media). In the present research, we propose and demonstrate in eight preregistered experiments ( N = 953) that such active sampling of information increases the truth effect, leading to an enhanced belief in information one had initially been exposed to following one&#39;s active choice. We further test both stimulus-based explanations (i.e., people are more likely to sample information that is perceived to be more plausible) and processing-based explanations (i.e., sampling information boosts cognitive processes that also increase the truth effect), with evidence favoring the latter account. Overall, our findings imply that repeated exposure to information has a more profound influence on people&#39;s beliefs in settings where people actively choose which information they are exposed to. (PsycInfo Database Record (c) 2026 APA, all rights reserved).</span>
                </div>
              </div>
            </div>
            
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Facts over partisanship: Evidence-based updating of trust in partisan sources. 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>Participants repeatedly evaluate messages from partisan sources and learn which sources are reliable via feedback, showing initial partisan bias that diminishes as Bayesian-like updating occurs; the paper provides process-oriented evidence on how people assess information credibility under uncertainty.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Lois, G., Tsakas, E., Riedl, A.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.36</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1037/xge0001815' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1037/xge0001815</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">A prominent explanation for the proliferation of political misinformation and the growing belief polarization is that people engage in motivated reasoning to affirm their ideology and to protect their political identities. An alternative explanation is that people seek the truth but use partisanship as a heuristic to discern credible from dubious sources of political information. In three experiments, we test these competing explanations in a dynamic setting where participants are repeatedly exposed to messages from ingroup or outgroup partisan sources and can learn which source is reliable based on external feedback. Participants initially showed a partisan bias as they incorporated information from ingroup sources more than from outgroup sources. This pattern was stronger among partisans that displayed high affective polarization. With experience, this partisan bias declined or even changed direction, as supporters of both groups gradually incorporated information from reliable sources more than unreliable sources irrespective of the source&#39;s partisanship. Importantly, the content of the shared information (i.e., neutral vs. political), the presence of partisan sources as opposed to neutral sources and the presence of external monetary accuracy incentives did not affect the learning process indicating the presence of strong internal accuracy motives. In contrast, increased uncertainty regarding source reliability undermined the learning process. These findings demonstrate that partisans follow Bayesian learning dynamics. Although participants initially display a partisan bias in the incorporation of information, they overcome this bias in the presence of external feedback and learn to trust credible sources irrespective of partisanship. (PsycInfo Database Record (c) 2025 APA, all rights reserved).</span>
                </div>
              </div>
            </div>
            
        <a id="journal-obhdp"></a>
        <h2 style="
            margin:34px 0 10px;
            font-size:24px;
            color:#b91c1c;
        ">
        OBHDP
        </h2>
        
            <div style="
                background:#ffffff;
                border:1px solid #e5e7eb;
                border-radius:14px;
                padding:18px;
                margin:14px 0 18px;
                box-shadow:0 2px 10px rgba(0,0,0,0.04);
            ">
              <h3 style="margin:0 0 10px;font-size:20px;color:#111827;">
                Targeting behavioral interventions based on past behavior: Evidence from vaccine uptake 
                
              </h3>

              <p style='margin:0 0 12px;font-size:14px;color:#374151;line-height:1.6;'>An applied experimental study showing that gain frames promote COVID-19 vaccination uptake more than loss frames, while emotional frames reduce perceived risk; the results are interpreted through Prospect Theory and TPB with predictors like attitudes, norms, and perceived control.</p>

              <div style="font-size:13px;color:#4b5563;line-height:1.7;">
                <div><b>Authors:</b> Brody, I., Dai, H., Saccardo, S., Milkman, K., Duckworth, A., Patel, M., Gromet, D.</div>
                <div><b>Published:</b> 2026-01</div>
                <div><b>Relevance Score:</b> 0.37</div>
                <div style="margin-top:10px;">
                  <b>DOI:</b>
                  <a href='https://doi.org/10.1016/j.obhdp.2025.104465' target='_blank' rel='noopener noreferrer' style='color:#2563eb;text-decoration:none;'>https://doi.org/10.1016/j.obhdp.2025.104465</a>
                  
                </div>

                <div style="
                    margin-top:12px;
                    padding:12px;
                    background:#f9fafb;
                    border:1px solid #eef0f4;
                    border-radius:12px;
                ">
                  <b>Abstract:</b><br>
                  <span style="color:#374151;">Objectives The Healthy China 2030 strategy outlines the government&#39;s plans for healthcare reform, emphasizing the need for increased awareness about infectious diseases to prevent and fight future infections. Information campaigns can be used as a medium to raise awareness and encourage citizens’ willingness to protect themselves against diseases, such as COVID-19. Extant studies have found that individual health behavior decision-making can be changed under different information frames. However, limited evidence is available about emerging infectious diseases. Based on the Prospect Theory and Theory of Planned Behavior, the impact of information frames on self-protective behavior—vaccination against COVID-19 is investigated in this study. Methods A 2(gain/loss frame)*2(factual/emotional frame) intergroup experimental design was designed to explore the effects of different information frames. 228 valid participants in China were recruited and the experiment was performed online. Results First, the gain frame was more effective in promoting public self-protection behavior than the loss frame under information frame intervention. Compared with the factual frame, the emotional frame is more effective in reducing individual risk perception. Second, perceptual behavior control has masking effects on self-protection behavior under the influence of the gain/loss frame. Third, age, subjective norms, attitudes, and the gain frame, have predictive effects on self-protection behavior. Conclusions This study provides empirical evidence on the impact of information framing interventions on public self-protection behavior during the COVID-19 pandemic and provides important practical implications for public administrators and media practitioners.</span>
                </div>
              </div>
            </div>
            
      </div>
      <a href="#top" class="back-to-top" aria-label="Back to top">
        ↑
        </a>

    </body>
    </html>
    